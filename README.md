# ğŸš€ Autonomous Product Experimentation Agent

An AI-powered autonomous experimentation system that uses multi-agent AI (CrewAI) to generate product ideas, design A/B experiments, run Bayesian statistical analysis, and make data-driven shipping decisions.

## âœ¨ Features

- **ğŸ¤– Multi-Agent AI System**: CrewAI agents collaborate to generate ideas, formulate hypotheses, and design experiments
- **ğŸ“Š Bayesian A/B Testing**: Probabilistic inference with PyMC (with automatic fallback to analytical approximation)
- **ğŸ¯ Autonomous Decision Making**: SHIP/ROLLBACK/ITERATE decisions based on Bayesian evidence
- **ğŸ“ˆ Interactive Dashboard**: Real-time visualization of experiment results and trends
- **ğŸ”„ End-to-End Pipeline**: From idea generation to decision-making, fully automated

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CrewAI Agents   â”‚  â†’ Idea Generation, Hypothesis, Design
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Experiment     â”‚  â†’ User Simulation, Data Collection
â”‚  Execution      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bayesian       â”‚  â†’ Probabilistic Inference & Analysis
â”‚  Analysis        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Decision       â”‚  â†’ Autonomous Decision Making
â”‚  Engine         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard      â”‚  â†’ Streamlit Visualization
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

- **Multi-Agent AI**: CrewAI, LangChain
- **Statistical Analysis**: PyMC, SciPy (Bayesian inference with automatic fallback)
- **Data Science**: NumPy
- **Visualization**: Streamlit, Matplotlib
- **Type Safety**: Pydantic
- **Testing**: pytest

## ğŸ“‹ Prerequisites

- Python 3.10 or higher
- OpenAI API key (or compatible LLM provider)
- Virtual environment (recommended)

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
git clone <repository-url>
cd project1
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configure Environment

Create a `.env` file in the root directory:

```bash
OPENAI_API_KEY=your_api_key_here
```

### 3. Run an Experiment

```bash
python main.py
```

This will:
- Run the complete experimentation pipeline
- Generate product ideas using CrewAI agents
- Design and execute A/B experiments
- Perform Bayesian analysis
- Make autonomous decisions
- Log results to `memory/experiment_memory.json`

### 4. Launch Dashboard

```bash
streamlit run dashboard/app.py
```

The dashboard will open automatically in your browser at `http://localhost:8501`.

**Note:** Run at least one experiment before viewing the dashboard.

## ğŸ“ Project Structure

```
project1/
â”œâ”€â”€ main.py                 # Main execution script
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ pytest.ini             # Pytest configuration
â”œâ”€â”€ .env                   # Environment variables (create this)
â”‚
â”œâ”€â”€ crew/                  # CrewAI multi-agent system
â”‚   â”œâ”€â”€ agents.yaml        # Agent configurations
â”‚   â”œâ”€â”€ tasks.yaml         # Task definitions
â”‚   â”œâ”€â”€ agents.py          # Agent loader
â”‚   â”œâ”€â”€ tasks.py           # Task loader
â”‚   â””â”€â”€ crew.py            # Crew setup
â”‚
â”œâ”€â”€ engine/                # Core experimentation engine
â”‚   â”œâ”€â”€ bayesian.py        # Bayesian A/B testing
â”‚   â”œâ”€â”€ simulator.py       # User behavior simulation
â”‚   â”œâ”€â”€ decision_rule.py   # Decision logic
â”‚   â”œâ”€â”€ memory.py          # Experiment logging
â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”‚
â”œâ”€â”€ dashboard/             # Streamlit dashboard
â”‚   â””â”€â”€ app.py            # Main dashboard
â”‚
â”œâ”€â”€ tests/                 # Unit tests
â”‚   â”œâ”€â”€ test_bayesian.py
â”‚   â”œâ”€â”€ test_decision_rule.py
â”‚   â””â”€â”€ test_simulator.py
â”‚
â””â”€â”€ memory/               # Experiment memory storage
    â””â”€â”€ experiment_memory.json
```

## ğŸ”¬ Key Features Explained

### Bayesian A/B Testing

Uses probabilistic inference to:
- Compute posterior distributions for conversion rates
- Provide credible intervals (not confidence intervals)
- Calculate probability that treatment > control
- No reliance on p-values or null hypothesis testing

**Automatic Fallback**: If PyMC compilation fails (common on Windows), the system automatically uses an analytical approximation with identical statistical properties.

### Autonomous Decision Making

Decision logic based on Bayesian evidence:
- **SHIP**: High confidence (P â‰¥ 0.95) that treatment is better
- **ROLLBACK**: Low confidence (P â‰¤ 0.60) that treatment is better  
- **ITERATE**: Medium confidence - needs more data or refinement

### Multi-Agent System

Five specialized AI agents:
1. **Idea Agent**: Product growth strategist
2. **Hypothesis Agent**: Causal inference analyst
3. **Design Agent**: Experiment design specialist
4. **Evaluation Agent**: Bayesian statistician
5. **Decision Agent**: Autonomous decision maker

## ğŸ“Š Dashboard Features

- **Latest Experiment Results**: Decision, posterior lift, probability metrics
- **Posterior Lift Distribution**: 95% credible interval visualization
- **Decision History**: Distribution of SHIP/ROLLBACK/ITERATE decisions
- **Experiment Trends**: Cumulative regret and lift over time
- **Experiment Details**: Full JSON view of experiment configuration

## ğŸ§ª Testing

Run the test suite:

```bash
pytest tests/
```

Or run specific tests:

```bash
pytest tests/test_bayesian.py
pytest tests/test_decision_rule.py
pytest tests/test_simulator.py
```

## ğŸ”§ Configuration

### Decision Thresholds

Modify thresholds in `engine/decision_rule.py`:

```python
SHIP_THRESHOLD = 0.95      # Probability threshold for SHIP
ROLLBACK_THRESHOLD = 0.60  # Probability threshold for ROLLBACK
```

### Agent Configuration

Customize agent behavior in:
- `crew/agents.yaml` - Agent roles, goals, and backstories
- `crew/tasks.yaml` - Task descriptions and expected outputs

### Sample Size Defaults

If sample size is not specified in experiment design, defaults to 1000 per variant (configurable in `main.py`).

## ğŸ› Troubleshooting

### PyMC Compilation Issues

If you see compilation errors on Windows, don't worry! The system automatically falls back to an analytical approximation that provides identical statistical results. This is handled transparently.

### Module Not Found Errors

Make sure you're running commands from the project root directory. The dashboard automatically adds the project root to Python's path.

### Empty Dashboard

Run at least one experiment (`python main.py`) before viewing the dashboard. The dashboard reads from `memory/experiment_memory.json`.

## ğŸ“ˆ Example Output

```
============================================================
AUTONOMOUS EXPERIMENT RESULT
============================================================

Idea: Change CTA button color from blue to green

Hypothesis: Green CTA will increase conversion rate by 2-3%

Bayesian Analysis:
   - Posterior Lift: 1.85%
   - P(Treatment > Control): 0.8723
   - 95% Credible Interval: [0.0045, 0.0321]

Decision: ITERATE
============================================================
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

Built as a demonstration of autonomous experimentation systems combining:
- Multi-agent AI (CrewAI)
- Bayesian statistics (PyMC/SciPy)
- Product decision-making
- Data visualization (Streamlit)

---

**Note**: This is a demonstration project. For production use, consider additional factors around data privacy, model validation, and system reliability.
